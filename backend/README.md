# Backend API for RAG System

This document provides instructions on how to set up, run, and test the FastAPI backend for the Retrieval Augmented Generation (RAG) system. This backend handles document processing, storage, and querying.

## Prerequisites

- Python 3.9+
- `uv` (or `pip` and a virtual environment manager)
- An embedding model will be downloaded on first use (default: `sentence-transformers/all-MiniLM-L6-v2`).

## Project Structure

The backend is organized as follows:

-   `app/`: The main application module.
    -   `api/v1/`: Contains the API endpoint modules:
        -   `documents.py`: Endpoints for document uploading, listing, and deletion.
        -   `rag.py`: Endpoints for querying the RAG system.
    -   `core/`: Houses core logic:
        -   `vector_store.py`: Manages interactions with the Chroma vector database.
        -   `llm_services.py`: Placeholder for LLM service interactions (currently, RAG responses are mocked).
-   `chroma_data/`: Default local storage directory for the Chroma vector database. This is created when the application first initializes the database.
-   `main.py`: The FastAPI application entry point that initializes the app and includes the API routers.
-   `pyproject.toml`: Defines project metadata and dependencies, managed by `uv` or `pip`.
-   `uv.lock`: The lock file generated by `uv` for reproducible builds.
-   `schemas.py`: Contains Pydantic models for request and response data validation.

## Setup and Running

1.  **Navigate to the backend directory:**
    ```bash
    cd backend
    ```

2.  **Create a virtual environment (recommended) and install dependencies:**
    If using `uv`:
    ```bash
    uv venv
    source .venv/bin/activate  # On Windows: .venv\Scripts\activate
    # Install dependencies from pyproject.toml
    uv pip install fastapi uvicorn[standard] chromadb langchain sentence-transformers pypdf python-multipart
    ```
    *(Ensure all necessary dependencies as listed in your `pyproject.toml` for the core RAG and document management functionality are included here. The command above lists the essential ones.)*

3.  **Run the FastAPI application:**
    ```bash
    uvicorn main:app --reload --host 0.0.0.0 --port 8000
    ```
    The API will be available at `http://localhost:8000`.

## API Endpoints and Testing

The API documentation (Swagger UI) is available at `http://localhost:8000/api/v1/docs` when the server is running. This provides an interactive way to test endpoints.

Below are `curl` examples for testing each endpoint.

### 1. Document Management Endpoints

Base URL: `http://localhost:8000/api/v1/documents`

#### a. Upload Documents

*   **Endpoint:** `POST /upload`
*   **Description:** Uploads one or more text or PDF files for processing and storage in the vector database.
*   **Example `curl` command:**
    First, create a sample text file named `sample.txt`:
    ```
    Hello world. This is a test document.
    RAG systems are interesting.
    ```
    Then, run the curl command (replace `/path/to/your/sample.txt` with the actual path if it's not in the current directory):
    ```bash
    curl -X POST -F "files=@sample.txt" http://localhost:8000/api/v1/documents/upload
    ```
    To upload multiple files:
    ```bash
    curl -X POST -F "files=@/path/to/your/file1.txt" -F "files=@/path/to/your/file2.pdf" http://localhost:8000/api/v1/documents/upload
    ```
*   **Expected Response:** A JSON array with details of the uploaded files, including a `id` (which is the `source_document_id`) for each.
    ```json
    [
      {
        "id": "some-uuid-for-sample.txt",
        "filename": "sample.txt",
        "status": "processed"
      }
    ]
    ```

#### b. List Documents

*   **Endpoint:** `GET /`
*   **Description:** Lists unique source documents that have been processed and indexed.
*   **Example `curl` command:**
    ```bash
    curl -X GET "http://localhost:8000/api/v1/documents/?limit=10&offset=0"
    ```
*   **Expected Response:** A JSON object with a list of documents and pagination details.
    ```json
    {
      "documents": [
        {
          "id": "some-uuid-for-sample.txt",
          "filename": "sample.txt",
          "status": "indexed",
          "indexed_chunks": 2,
          "added_on": "YYYY-MM-DDTHH:MM:SS.ffffff", // Actual timestamp
          "metadata": {} // Or actual metadata if stored
        }
      ],
      "total": 1,
      "limit": 10,
      "offset": 0
    }
    ```

#### c. Get Document Details

*   **Endpoint:** `GET /{document_id}`
*   **Description:** Retrieves details for a specific source document using its ID.
*   **Example `curl` command (replace `your_document_id` with an ID from the upload or list response):**
    ```bash
    curl -X GET http://localhost:8000/api/v1/documents/your_document_id
    ```
*   **Expected Response:** JSON object with document details.
    ```json
    {
      "id": "your_document_id",
      "filename": "sample.txt",
      "status": "indexed",
      "indexed_chunks": 2,
      "added_on": "YYYY-MM-DDTHH:MM:SS.ffffff",
      "metadata": {}
    }
    ```

#### d. Delete Document

*   **Endpoint:** `DELETE /{document_id}`
*   **Description:** Deletes a document and all its associated chunks from the vector store.
*   **Example `curl` command (replace `your_document_id` with an ID):**
    ```bash
    curl -X DELETE http://localhost:8000/api/v1/documents/your_document_id
    ```
*   **Expected Response:** Confirmation message.
    ```json
    {
      "message": "Document your_document_id and its X chunks deleted successfully."
    }
    ```

### 2. RAG System Endpoint

Base URL: `http://localhost:8000/api/v1/rag`

#### a. Query the RAG System

*   **Endpoint:** `POST /query`
*   **Description:** Submits a query to the RAG system. Retrieves relevant documents and generates an LLM response.
    **Note:** Currently, the LLM response generation is mocked in `backend/app/api/v1/rag.py`.
*   **Example `curl` command:**
    ```bash
    curl -X POST -H "Content-Type: application/json" \
    -d '{
      "query": "What are RAG systems?",
      "top_k": 3
    }' \
    http://localhost:8000/api/v1/rag/query
    ```
*   **Expected Response:** JSON object with the answer and source documents.
    ```json
    {
      "answer": "This is a mock answer to your query: 'What are RAG systems?'. Actual LLM integration is pending.",
      "sources": [
        {
          "id": "some-uuid-for-sample.txt",
          "document_name": "sample.txt",
          "snippet": "RAG systems are interesting.",
          "score": 0.85
        }
      ],
      "query_time_ms": 123.45
    }
    ```
